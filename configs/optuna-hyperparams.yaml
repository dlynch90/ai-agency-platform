hyperparameter_optimization:
  framework: optuna
  storage: ${OPTUNA_STORAGE:-sqlite:///data/optuna.db}
  
  study:
    name: ai-agency-llm-optimization
    direction: maximize
    sampler:
      type: TPESampler
      multivariate: true
      n_startup_trials: 10
    pruner:
      type: MedianPruner
      n_startup_trials: 5
      n_warmup_steps: 10

  search_space:
    model:
      type: categorical
      choices:
        - llama3.2
        - codellama
        - deepseek-coder-v2
        - gpt-4o
        - claude-sonnet-4
        - gemini-1.5-pro
    
    temperature:
      type: float
      low: 0.0
      high: 2.0
      step: 0.1
    
    top_p:
      type: float
      low: 0.1
      high: 1.0
      step: 0.1
    
    max_tokens:
      type: int
      low: 256
      high: 4096
      step: 256
    
    frequency_penalty:
      type: float
      low: 0.0
      high: 2.0
      step: 0.1
    
    presence_penalty:
      type: float
      low: 0.0
      high: 2.0
      step: 0.1

  objectives:
    primary:
      metric: accuracy
      direction: maximize
      threshold: 0.85
    
    secondary:
      - metric: latency_ms
        direction: minimize
        weight: 0.3
        threshold: 2000
      
      - metric: cost_per_1k_tokens
        direction: minimize
        weight: 0.2
        threshold: 0.05

  evaluation:
    metrics:
      - name: answer_relevancy
        threshold: 0.7
        weight: 0.25
      
      - name: faithfulness
        threshold: 0.8
        weight: 0.25
      
      - name: hallucination
        threshold: 0.9
        weight: 0.2
      
      - name: bias
        threshold: 0.8
        weight: 0.15
      
      - name: toxicity
        threshold: 0.95
        weight: 0.15

  trials:
    n_trials: 100
    n_jobs: 4
    timeout: 3600
    gc_after_trial: true

  callbacks:
    mlflow:
      enabled: true
      tracking_uri: ${MLFLOW_TRACKING_URI:-http://localhost:5000}
      experiment_name: ai-agency-hyperparameter-optimization
      log_system_metrics: true
    
    pruning:
      enabled: true
      patience: 10

  use_case_specific:
    ECOMMERCE_PERSONALIZATION:
      model_preference: [llama3.2, gpt-4o]
      temperature_range: [0.3, 0.7]
      focus_metrics: [answer_relevancy, faithfulness]
    
    HEALTHCARE_TRIAGE:
      model_preference: [gpt-4o, claude-sonnet-4]
      temperature_range: [0.1, 0.3]
      focus_metrics: [hallucination, faithfulness]
    
    FINANCIAL_PORTFOLIO:
      model_preference: [gpt-4o, claude-sonnet-4]
      temperature_range: [0.0, 0.3]
      focus_metrics: [faithfulness, accuracy]
    
    LEGAL_DOCUMENT:
      model_preference: [claude-sonnet-4, gpt-4o]
      temperature_range: [0.0, 0.2]
      focus_metrics: [faithfulness, hallucination]
    
    CUSTOMER_SERVICE:
      model_preference: [llama3.2, gpt-4o]
      temperature_range: [0.5, 0.8]
      focus_metrics: [answer_relevancy, toxicity]

mlflow_integration:
  autolog:
    models: true
    input_examples: true
    signatures: true
  
  model_registry:
    enabled: true
    stage_transitions:
      - from: None
        to: Staging
        condition: accuracy >= 0.85
      - from: Staging
        to: Production
        condition: accuracy >= 0.90 AND latency_ms < 1500

reporting:
  output_dir: reports/optuna
  formats:
    - json
    - html
  
  plots:
    - optimization_history
    - param_importances
    - contour
    - parallel_coordinate
