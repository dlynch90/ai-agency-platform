#!/usr/bin/env python3
"""
SERVICE INITIALIZER FOR VENDOR COMPLIANCE SYSTEM
===============================================

Initializes all required services in proper order to avoid race conditions:
- MCP servers
- ML inference services
- Vendor tool integrations
- Cursor IDE optimizations
- GPU acceleration services
"""

import os
import sys
import json
import time
import subprocess
from pathlib import Path
from typing import Dict, List, Any

class ServiceInitializer:
    def __init__(self):
        self.services = {
            'ollama': {'port': 11434, 'health_check': 'http://localhost:11434/api/tags'},
            'mcp_server': {'port': 7243, 'endpoint': '/ingest/5072b9ca-f4c1-41f0-9e47-ea0a9f90dfab'},
            'temporal': {'port': 7233, 'health_check': 'http://localhost:7233/health'},
            'redis': {'port': 6379, 'health_check': 'redis-cli ping'},
            'postgres': {'port': 5432, 'health_check': 'pg_isready -h localhost'}
        }
        self.initialization_order = [
            'infrastructure',
            'database',
            'cache',
            'ml_inference',
            'mcp_servers',
            'vendor_tools',
            'cursor_optimization'
        ]

    def initialize_services(self) -> Dict[str, Any]:
        """Initialize all services in proper order"""
        results = {}

        #region agent log H5: Service Initialization Race Condition
        import json
        log_entry = {
            "sessionId": "debug-session-20part",
            "runId": "initial-run",
            "hypothesisId": "H5",
            "location": "scripts/service-initializer.py:35",
            "message": "Starting service initialization sequence",
            "data": {
                "initialization_order": self.initialization_order,
                "services_to_start": list(self.services.keys())
            },
            "timestamp": int(time.time() * 1000)
        }
        with open('/Users/daniellynch/Developer/.cursor/debug.log', 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
        #endregion

        for phase in self.initialization_order:
            print(f"ðŸš€ Initializing {phase} services...")
            try:
                if phase == 'infrastructure':
                    results[phase] = self._init_infrastructure()
                elif phase == 'database':
                    results[phase] = self._init_database()
                elif phase == 'cache':
                    results[phase] = self._init_cache()
                elif phase == 'ml_inference':
                    results[phase] = self._init_ml_inference()
                elif phase == 'mcp_servers':
                    results[phase] = self._init_mcp_servers()
                elif phase == 'vendor_tools':
                    results[phase] = self._init_vendor_tools()
                elif phase == 'cursor_optimization':
                    results[phase] = self._init_cursor_optimization()

                #region agent log H5: Phase Completion
                log_entry = {
                    "sessionId": "debug-session-20part",
                    "runId": "initial-run",
                    "hypothesisId": "H5",
                    "location": "scripts/service-initializer.py:60",
                    "message": f"Completed {phase} initialization",
                    "data": {
                        "phase": phase,
                        "success": results[phase].get('success', False),
                        "services_started": results[phase].get('services', [])
                    },
                    "timestamp": int(time.time() * 1000)
                }
                with open('/Users/daniellynch/Developer/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps(log_entry) + '\n')
                #endregion

            except Exception as e:
                print(f"âŒ Failed to initialize {phase}: {e}")
                results[phase] = {'success': False, 'error': str(e)}

        return results

    def _init_infrastructure(self) -> Dict:
        """Initialize basic infrastructure services"""
        services_started = []

        # Check if Docker is running
        try:
            result = subprocess.run(['docker', 'info'], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                services_started.append('docker')
        except:
            pass

        return {'success': True, 'services': services_started}

    def _init_database(self) -> Dict:
        """Initialize database services"""
        services_started = []

        # Check PostgreSQL
        try:
            result = subprocess.run(['pg_isready', '-h', 'localhost'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                services_started.append('postgres')
        except:
            pass

        return {'success': True, 'services': services_started}

    def _init_cache(self) -> Dict:
        """Initialize cache services"""
        services_started = []

        # Check Redis
        try:
            result = subprocess.run(['redis-cli', 'ping'], capture_output=True, text=True, timeout=5)
            if 'PONG' in result.stdout:
                services_started.append('redis')
        except:
            pass

        return {'success': True, 'services': services_started}

    def _init_ml_inference(self) -> Dict:
        """Initialize ML inference services"""
        services_started = []

        # Check Ollama
        try:
            import requests
            response = requests.get('http://localhost:11434/api/tags', timeout=5)
            if response.status_code == 200:
                services_started.append('ollama')

                # Check for available models
                models = response.json().get('models', [])
                services_started.extend([f"ollama:{model['name']}" for model in models])
        except:
            pass

        #region agent log H4: GPU Acceleration Configuration - ML Services Check
        log_entry = {
            "sessionId": "debug-session-20part",
            "runId": "initial-run",
            "hypothesisId": "H4",
            "location": "scripts/service-initializer.py:130",
            "message": "ML inference services initialization status",
            "data": {
                "ollama_available": 'ollama' in services_started,
                "models_loaded": [s for s in services_started if s.startswith('ollama:')],
                "gpu_acceleration_available": self._check_gpu_acceleration()
            },
            "timestamp": int(time.time() * 1000)
        }
        with open('/Users/daniellynch/Developer/.cursor/debug.log', 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
        #endregion

        return {'success': True, 'services': services_started}

    def _init_mcp_servers(self) -> Dict:
        """Initialize MCP servers"""
        services_started = []

        # Check MCP server endpoint
        try:
            import requests
            response = requests.get('http://localhost:7243/health', timeout=5)
            if response.status_code == 200:
                services_started.append('mcp_server')
        except:
            pass

        return {'success': True, 'services': services_started}

    def _init_vendor_tools(self) -> Dict:
        """Initialize vendor tools"""
        services_started = []

        tools_to_check = ['chezmoi', 'pixi', 'mise', 'gh', 'op']

        for tool in tools_to_check:
            try:
                result = subprocess.run([tool, '--version'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    services_started.append(tool)
            except:
                pass

        return {'success': True, 'services': services_started}

    def _init_cursor_optimization(self) -> Dict:
        """Initialize Cursor IDE optimizations"""
        services_started = []

        # Check for Cursor-specific configurations
        cursor_config_dir = Path.home() / '.cursor'
        if cursor_config_dir.exists():
            services_started.append('cursor_config')

            # Check for MCP configurations
            mcp_dir = cursor_config_dir / 'mcp'
            if mcp_dir.exists():
                services_started.append('cursor_mcp_config')

        # Check for GPU acceleration in Cursor
        gpu_config = cursor_config_dir / 'gpu-config.json'
        if gpu_config.exists():
            services_started.append('cursor_gpu_config')

        #region agent log H4: GPU Acceleration Configuration - Cursor IDE Setup
        log_entry = {
            "sessionId": "debug-session-20part",
            "runId": "initial-run",
            "hypothesisId": "H4",
            "location": "scripts/service-initializer.py:185",
            "message": "Cursor IDE optimization configuration check",
            "data": {
                "cursor_config_exists": cursor_config_dir.exists(),
                "mcp_config_exists": (cursor_config_dir / 'mcp').exists(),
                "gpu_config_exists": gpu_config.exists(),
                "optimization_services": services_started
            },
            "timestamp": int(time.time() * 1000)
        }
        with open('/Users/daniellynch/Developer/.cursor/debug.log', 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
        #endregion

        return {'success': True, 'services': services_started}

    def _check_gpu_acceleration(self) -> Dict:
        """Check GPU acceleration availability"""
        gpu_info = {
            'cuda_available': False,
            'metal_available': False,
            'gpu_memory': None
        }

        try:
            # Check for CUDA (NVIDIA)
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                gpu_info['cuda_available'] = True
        except:
            pass

        try:
            # Check for Metal (Apple Silicon)
            result = subprocess.run(['system_profiler', 'SPDisplaysDataType'], capture_output=True, text=True, timeout=5)
            if 'Metal' in result.stdout:
                gpu_info['metal_available'] = True
        except:
            pass

        return gpu_info

def main():
    initializer = ServiceInitializer()
    results = initializer.initialize_services()

    # Generate initialization report
    report = {
        'timestamp': int(time.time() * 1000),
        'initialization_results': results,
        'overall_success': all(phase.get('success', False) for phase in results.values())
    }

    report_path = Path('reports/service-initialization-report.json')
    report_path.parent.mkdir(exist_ok=True)

    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)

    print(f"ðŸ“Š Service initialization report saved to: {report_path}")

    # Summary
    total_services = sum(len(phase.get('services', [])) for phase in results.values())
    successful_phases = sum(1 for phase in results.values() if phase.get('success', False))

    print(f"ðŸŽ¯ Initialization Summary: {successful_phases}/{len(results)} phases successful")
    print(f"ðŸ”§ Total services started: {total_services}")

if __name__ == '__main__':
    main()